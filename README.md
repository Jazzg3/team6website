![logo](/images/logo.jpg)
### Team members: Bao Thy Nguyen, Garno Amirian, Aidan Garamendi 
# Project Description

### The Problem:
People who are dealing with hearing loss or unable to speak face challenges in communicating with those unfamiliar with sign language without an interpreter. 

### The Solution:
A live closed captioning system for ASL, utilizing machine learning and displays the translation onto an OLED display attached to the person signing.

(insert favorite photos collage)

![logo](/images/schematic1.png) 
![logo](/images/collage.png)


# The Team

### Bao Thy Nguyen

![logo](/images/blank.jpg)

Bao Thy is a Computer Engineering Senior without experience in both industrial level power engineering at IEM Power Systems and small scale robotics electronics with Yonder Deep Robotics on campus

### Garno Amirian

![logo](/images/blank.jpg)

Garno is an Eletrical Engineering Senior with a Circuit Engineering depth, without experience in both industrial level power engineering at IEM Power Systems and small scale robotics electronics with Yonder Deep Robotics on campus

### Aidan Garamendi

![logo](/images/blank.jpg)

Aidan is an Eletrical Engineering Senior in the Power Engineering depth, with experience in both industrial level power engineering and small scale robotics.


# Video Demo 
[![Presentation Video ](https://img.youtube.com/vi/dQw4w9WgXcQ/0.jpg)](https://www.youtube.com/watch?v=dQw4w9WgXcQ)

# Final Presentation Slide Deck
[![slide deck ](/images/slidedeck.png)](https://docs.google.com/presentation/d/1VO9xiTrAwZHm3HV66OTTplPPoqh0uB_zesGNIXyZNLo/edit#slide=id.g2ce5c1ef43d_0_275)

# Bibliography
* ECE 16 libraries for arduino and python

* 28 image classification dataset from Kaggle

* Pre Trained EfficientNet for testing

* EfficientNet for training and implementation
