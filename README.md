![logo](/images/logo.jpg)
### Team members: Bao Thy Nguyen, Garno Amirian, Aidan Garamendi 
## Project Description

The problem weâ€™ve chosen is the lack of effective communication methods for deaf/mute individuals to easily interact with those who are unfamiliar with sign language without the aid of an interpreter, which creates distance between these communities.

Our proposed solution is to create a video input device that will detect movements and use a machine learning algorithm to assign those to classes that represent words or letters in the american sign language alphabet. This would then be wirelessly transmitted and displayed on a wearable device to allow others to understand what the individual is signing.

(insert favorite photos collage)
![logo](/images/schematic1.png =150x) ![logo](/images/schematic2.png =150x)


## The Team

### Bao Thy Nguyen

![logo](/images/blank.jpg)

brief bio

### Garno Amirian

![logo](/images/blank.jpg)

brief bio

### Aidan Garamendi

![logo](/images/blank.jpg)

brief bio


## Video Demo 
[![Presentation Video](https://img.youtube.com/vi/dQw4w9WgXcQ/0.jpg)](https://www.youtube.com/watch?v=dQw4w9WgXcQ)

## Slide Deck
(embed slide deck)

## Bibliography
sources:
